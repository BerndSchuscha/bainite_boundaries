{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:107: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:107: SyntaxWarning: invalid escape sequence '\\p'\n",
      "/tmp/ipykernel_1022715/1473400385.py:107: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  return f\"${rounded_value:.{decimal_places}f}_{{\\pm {rounded_uncertainty:.{decimal_places}f}}}$\"\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import bainite_boundaries\n",
    "project_root = os.path.abspath(Path(str(bainite_boundaries.PROJECT_ROOT), 'bainite_boundaries', 'bainite_boundaries'))\n",
    "\n",
    "# Add `bainite_boundaries` to sys.path if it’s not already present\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import gpytorch\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from bainite_boundaries.utils.data_processing import stable_log10\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def plot_and_compute_mean_over_cp_cv_folds(results: pd.DataFrame, column = 'y_test', title = ''):\n",
    "    # Dictionary to store the mean y_test values for each CV fold\n",
    "    total_results = []\n",
    "\n",
    "    # Loop over each CV fold\n",
    "    for index in results['CV_fold'].unique():\n",
    "        fold_data = results[results['CV_fold'] == index]\n",
    "        \n",
    "        # List to store the y_test values for each CP_CV_fold within the current CV fold\n",
    "        cp_mean_values = []\n",
    "        \n",
    "        # Loop over each CP_CV_fold for the current CV fold\n",
    "        for cp_fold in fold_data['CP_CV_fold'].unique():\n",
    "            cp_fold_data = fold_data[fold_data['CP_CV_fold'] == cp_fold]\n",
    "            \n",
    "            # Extract the y_test and convert it to a numpy array\n",
    "\n",
    "            string = cp_fold_data[column].iloc[0]  # Assuming the y_test for the same CP_CV_fold is the same\n",
    "            # if it is a string\n",
    "            if isinstance(string, str):\n",
    "                string = string.replace('\\n', ' ').strip('[]')\n",
    "                y_test_array = np.fromstring(string, dtype=float, sep=' ')\n",
    "            else:\n",
    "                y_test_array = string\n",
    "            \n",
    "            # Append the mean of y_test_array for this CP_CV_fold\n",
    "            cp_mean_values.append(y_test_array)\n",
    "            \n",
    "            # print( f\" CV_fold: {index}, CP_CV_fold: {cp_fold}, y_test: {y_test_array}\")\n",
    "        \n",
    "        # Calculate the mean over all CP_CV_folds for the current CV fold\n",
    "        total_results.append(np.mean(cp_mean_values, axis=0))\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Return the results\n",
    "    return total_results\n",
    "\n",
    "def round_uncertainty(value, uncertainty):\n",
    "    \"\"\"\n",
    "    Format mean and standard deviation according to scientific rounding rules.\n",
    "\n",
    "    Args:\n",
    "        value (float): Mean value.\n",
    "        uncertainty (float): Standard deviation (or uncertainty).\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted mean ± standard deviation string.\n",
    "    \"\"\"\n",
    "\n",
    "    # Rule: Uncertainty should have 1 or 2 significant digits\n",
    "    if uncertainty == 0:\n",
    "        return f\"{value:.2f} ± 0\"  # Handle zero case separately\n",
    "\n",
    "    # Get the order of magnitude of the uncertainty\n",
    "    order = np.floor(np.log10(abs(uncertainty)))\n",
    "\n",
    "    # Find first two significant digits\n",
    "    first_digit = int(uncertainty / 10**order)\n",
    "    second_digit = int((uncertainty / 10**(order - 1)) % 10)\n",
    "\n",
    "    # If first digit is 1, keep two significant digits; otherwise, keep one\n",
    "    if first_digit == 1:\n",
    "        rounded_uncertainty = round(uncertainty, -int(order - 1))\n",
    "    else:\n",
    "        rounded_uncertainty = round(uncertainty, -int(order))\n",
    "\n",
    "    # Determine decimal places for the mean\n",
    "    decimal_places = -int(np.floor(np.log10(rounded_uncertainty)))\n",
    "\n",
    "    # If uncertainty is a whole number, no decimal places\n",
    "    decimal_places = max(decimal_places, 0)\n",
    "\n",
    "    # Round the mean accordingly\n",
    "    rounded_value = round(value, decimal_places)\n",
    "    \n",
    "    # Format output string\n",
    "    return f\"${rounded_value:.{decimal_places}f}_{{\\pm {rounded_uncertainty:.{decimal_places}f}}}$\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear\n",
      "mahalanobis PCA_scaled\n",
      "MALE $0.046_{\\pm 0.007}$\n",
      "MAPE [%] $12_{\\pm 2}$\n",
      "MAE $30_{\\pm 2}$\n",
      "R2 $0.75_{\\pm 0.07}$\n",
      "R2log $-26_{\\pm 20}$\n",
      "coverage [%] $90_{\\pm 2}$\n",
      "coverage_distance [%] $91_{\\pm 2}$\n",
      "interval_size  $120_{\\pm 2}$\n",
      "interval_size_distance  $119_{\\pm 3}$\n",
      "interval_log_size $0.162_{\\pm 0.008}$\n",
      "interval_log_size_distance $0.16_{\\pm 0.01}$\n",
      "polynomial\n",
      "mahalanobis PCA_scaled\n",
      "MALE $0.091_{\\pm 0.005}$\n",
      "MAPE [%] $23_{\\pm 2}$\n",
      "MAE $63_{\\pm 2}$\n",
      "R2 $0.22_{\\pm 0.03}$\n",
      "R2log $-7_{\\pm 14}$\n",
      "coverage [%] $90_{\\pm 3}$\n",
      "coverage_distance [%] $90_{\\pm 3}$\n",
      "interval_size  $254_{\\pm 3}$\n",
      "interval_size_distance  $255_{\\pm 4}$\n",
      "interval_log_size $0.36_{\\pm 0.01}$\n",
      "interval_log_size_distance $0.36_{\\pm 0.01}$\n",
      "GP_linearmean\n",
      "mahalanobis PCA_scaled\n",
      "MALE $0.032_{\\pm 0.004}$\n",
      "MAPE [%] $8_{\\pm 1}$\n",
      "MAE $20_{\\pm 2}$\n",
      "R2 $0.88_{\\pm 0.03}$\n",
      "R2log $0.7_{\\pm 0.1}$\n",
      "coverage [%] $92_{\\pm 3}$\n",
      "coverage_distance [%] $92_{\\pm 2}$\n",
      "interval_size  $93_{\\pm 5}$\n",
      "interval_size_distance  $96_{\\pm 7}$\n",
      "interval_log_size $0.15_{\\pm 0.01}$\n",
      "interval_log_size_distance $0.15_{\\pm 0.01}$\n",
      "GP_Poly\n",
      "mahalanobis PCA_scaled\n",
      "MALE $0.035_{\\pm 0.008}$\n",
      "MAPE [%] $8_{\\pm 1}$\n",
      "MAE $21_{\\pm 2}$\n",
      "R2 $0.87_{\\pm 0.03}$\n",
      "R2log $-5_{\\pm 13}$\n",
      "coverage [%] $90_{\\pm 3}$\n",
      "coverage_distance [%] $90_{\\pm 4}$\n",
      "interval_size  $98_{\\pm 7}$\n",
      "interval_size_distance  $103_{\\pm 20}$\n",
      "interval_log_size $0.141_{\\pm 0.008}$\n",
      "interval_log_size_distance $0.143_{\\pm 0.006}$\n",
      "GP\n",
      "mahalanobis PCA_scaled\n",
      "MALE $0.030_{\\pm 0.005}$\n",
      "MAPE [%] $7_{\\pm 2}$\n",
      "MAE $20_{\\pm 2}$\n",
      "R2 $0.89_{\\pm 0.03}$\n",
      "R2log $0.85_{\\pm 0.06}$\n",
      "coverage [%] $91_{\\pm 2}$\n",
      "coverage_distance [%] $91_{\\pm 2}$\n",
      "interval_size  $91_{\\pm 3}$\n",
      "interval_size_distance  $94_{\\pm 6}$\n",
      "interval_log_size $0.13_{\\pm 0.01}$\n",
      "interval_log_size_distance $0.15_{\\pm 0.02}$\n",
      "RF\n",
      "knn PCA_scaled\n",
      "MALE $0.030_{\\pm 0.004}$\n",
      "MAPE [%] $7_{\\pm 1}$\n",
      "MAE $19_{\\pm 2}$\n",
      "R2 $0.90_{\\pm 0.03}$\n",
      "R2log $0.85_{\\pm 0.05}$\n",
      "coverage [%] $91_{\\pm 4}$\n",
      "coverage_distance [%] $90_{\\pm 4}$\n",
      "interval_size  $90_{\\pm 3}$\n",
      "interval_size_distance  $88_{\\pm 4}$\n",
      "interval_log_size $0.127_{\\pm 0.005}$\n",
      "interval_log_size_distance $0.13_{\\pm 0.01}$\n",
      "LGBM_no_monotonic\n",
      "mahalanobis PCA_scaled\n",
      "MALE $0.029_{\\pm 0.003}$\n",
      "MAPE [%] $7.2_{\\pm 0.9}$\n",
      "MAE $19_{\\pm 1}$\n",
      "R2 $0.90_{\\pm 0.01}$\n",
      "R2log $0.86_{\\pm 0.03}$\n",
      "coverage [%] $91_{\\pm 2}$\n",
      "coverage_distance [%] $91_{\\pm 1}$\n",
      "interval_size  $91_{\\pm 2}$\n",
      "interval_size_distance  $88_{\\pm 2}$\n",
      "interval_log_size $0.129_{\\pm 0.005}$\n",
      "interval_log_size_distance $0.128_{\\pm 0.006}$\n",
      "monoton_neural\n",
      "mahalanobis PCA_scaled\n",
      "MALE $0.096_{\\pm 0.006}$\n",
      "MAPE [%] $26_{\\pm 2}$\n",
      "MAE $68_{\\pm 3}$\n",
      "R2 $0.05_{\\pm 0.07}$\n",
      "R2log $0.04_{\\pm 0.07}$\n",
      "coverage [%] $91_{\\pm 3}$\n",
      "coverage_distance [%] $91_{\\pm 3}$\n",
      "interval_size  $280_{\\pm 5}$\n",
      "interval_size_distance  $269_{\\pm 4}$\n",
      "interval_log_size $0.390_{\\pm 0.007}$\n",
      "interval_log_size_distance $0.379_{\\pm 0.007}$\n"
     ]
    }
   ],
   "source": [
    "which_data = 'Austensite'\n",
    "which_data = 'Martensite_start'\n",
    "which_data = 'Martensite_start_RA'\n",
    "#which_data = 'Bainite_start'\n",
    "#which_data = 'Ferrite'\n",
    "#which_data = 'Ferrite_critCR'\n",
    "#which_data = 'Bainite'\n",
    "#'RF', 'XGB_no_monotonic', 'LGBM_no_monotonic'\n",
    "# 'linear','linear_mixed','polynomial','polynomial_mixed', 'neural', 'GP'\n",
    "model_names = {\n",
    "'Austensite': ['linear','neural_class'],#, 'GB_class', 'SVC_class'],\n",
    "'Bainite': ['linear','polynomial','GP_Poly','GP','RF','LGBM_no_monotonic','monoton_neural','GP_linearmean'],#,'polynomial','GP','GP_Poly','RF','XGB_no_monotonic','LGBM_no_monotonic','GP_linearmean','NN'],\n",
    "# 'Bainite': ['GP'],\n",
    "'Ferrite_critCR': ['linear', 'RF', 'XGB_no_monotonic', 'LGBM_no_monotonic','polynomial','GP_Poly','GP','neural'],#['linear', 'neural', 'neural_pt'],#['linear', 'neural_pt','neural_pt'],\n",
    "'Martensite_start':['linear','polynomial','GP_linearmean','GP_Poly','GP','RF','LGBM_no_monotonic','monoton_neural'],# ['monoton_neural','linear','polynomial','neural','neural_pt','random','GP','GP_Poly'],#,'GP_Poly'],\n",
    "'Martensite_start_RA':['linear','polynomial','GP_linearmean','GP_Poly','GP','RF','LGBM_no_monotonic','monoton_neural'],\n",
    "'Bainite_start': ['linear','polynomial','GP_linearmean','GP_Poly','GP','RF','LGBM_no_monotonic','monoton_neural']\n",
    "}[which_data]\n",
    "for model in model_names:\n",
    "    filename = f'./bainite_boundaries/results/k-fold-CV/{which_data}_{model}_results'\n",
    "    results = pd.read_csv(filename+'.csv')\n",
    "    # load pickle\n",
    "    # results = pd.read_pickle(filename+'.pkl')\n",
    "    # results.head()\n",
    "\n",
    "    if which_data == 'Austensite':\n",
    "        classification = True\n",
    "    else:\n",
    "        classification = False\n",
    "\n",
    "    from utils.data_processing import compute_metrics_regression\n",
    "    from utils.data_processing import compute_metrics_classification\n",
    "\n",
    "\n",
    "    if classification:\n",
    "\n",
    "        # labels and predictions\n",
    "        y_test = plot_and_compute_mean_over_cp_cv_folds(results, column='y_test', title='y_test')\n",
    "        y_pred_test_mean = plot_and_compute_mean_over_cp_cv_folds(results, column='y_pred_test', title='y_pred_test_mean')\n",
    "        y_pred_proba_test_mean = plot_and_compute_mean_over_cp_cv_folds(results, column='y_pred_proba_test', title='y_pred_proba_test_mean')\n",
    "\n",
    "        confidence_sets = plot_and_compute_mean_over_cp_cv_folds(results, column='confidence_sets_test', title='confidence_sets_test')\n",
    "        confidence_sets_distance = plot_and_compute_mean_over_cp_cv_folds(results, column='confidence_sets_distance_test', title='confidence_sets_distance_test')\n",
    "        \n",
    "        metrics_list = []\n",
    "        for i in range(len(y_test)):\n",
    "            prediction_dict = {\n",
    "                'y_true': y_test[i],\n",
    "                'y_pred': y_pred_test_mean[i],\n",
    "                'y_pred_proba': y_pred_proba_test_mean[i],\n",
    "                'confidence_sets': confidence_sets[i],\n",
    "                'confidence_sets_distance': confidence_sets_distance[i],\n",
    "            }\n",
    "\n",
    "            metrics_dict = compute_metrics_classification(prediction_dict)\n",
    "            metrics_list.append(metrics_dict)\n",
    "            \n",
    "    else:    \n",
    "\n",
    "        # labels and predictions\n",
    "        y_test = plot_and_compute_mean_over_cp_cv_folds(results, column='y_test', title='y_test')\n",
    "        y_pred_test_mean = plot_and_compute_mean_over_cp_cv_folds(results, column='y_pred_test', title='y_pred_test_mean')\n",
    "\n",
    "\n",
    "        # with distance\n",
    "        y_test_lower_distance = plot_and_compute_mean_over_cp_cv_folds(results, column='lower_CP_distance_test', title='y_test_lower')\n",
    "        y_test_upper_distance = plot_and_compute_mean_over_cp_cv_folds(results, column='upper_CP_distance_test', title='y_test_upper')\n",
    "\n",
    "        # no distance\n",
    "        y_test_lower = plot_and_compute_mean_over_cp_cv_folds(results, column='lower_CP_test', title='y_test_lower')\n",
    "        y_test_upper = plot_and_compute_mean_over_cp_cv_folds(results, column='upper_CP_test', title='y_test_upper')\n",
    "\n",
    "        metrics_list = []\n",
    "        for i in range(len(y_test)):\n",
    "            prediction_dict = {\n",
    "                'y_true': y_test[i],\n",
    "                'y_pred': y_pred_test_mean[i],\n",
    "                'lower_CP': y_test_lower[i],\n",
    "                'upper_CP': y_test_upper[i],\n",
    "                'lower_CP_distance': y_test_lower_distance[i],\n",
    "                'upper_CP_distance': y_test_upper_distance[i],\n",
    "            }\n",
    "\n",
    "            metrics_dict = compute_metrics_regression(prediction_dict)\n",
    "            metrics_list.append(metrics_dict)\n",
    "            \n",
    "    # Initialize containers for each metric\n",
    "    metrics_aggregated = {key: [] for key in metrics_list[0].keys()}\n",
    "\n",
    "    # Aggregate the values for each metric\n",
    "    for entry in metrics_list:\n",
    "        for key, value in entry.items():\n",
    "            metrics_aggregated[key].append(value)\n",
    "    print(model)\n",
    "    # Calculate the mean and std for each metric\n",
    "    metrics_summary = {key: {'mean': np.mean(values), 'std': np.std(values)} for key, values in metrics_aggregated.items()}\n",
    "    print(results['distance_metric'][0], results['distance_loc'][0])\n",
    "\n",
    "    #m_list=['MALE','R2log','coverage_distance [%]','interval_log_size_distance']\n",
    "    # Print the results\n",
    "    for metric, summary in metrics_summary.items():\n",
    "        #if metric in m_list:\n",
    "            #print(metric,summary['mean'], summary['std'])\n",
    "            print(metric,round_uncertainty(summary['mean'], summary['std']))\n",
    "        #print(f\"{metric}: $ {summary['mean']:.2f}_{{\\pm {summary['std']:.2f}}} $\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.006702324845382349)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MALE': [np.float64(0.10251546795285568),\n",
       "  np.float64(0.10819878308645933),\n",
       "  np.float64(0.08744839502647002),\n",
       "  np.float64(0.09669510551528955),\n",
       "  np.float64(0.09292707595459895),\n",
       "  np.float64(0.09682912977302906),\n",
       "  np.float64(0.09499436414506156),\n",
       "  np.float64(0.09914723847482607),\n",
       "  np.float64(0.08796363309719898),\n",
       "  np.float64(0.09119745911366674)],\n",
       " 'MAPE [%]': [np.float64(28.52981159363141),\n",
       "  np.float64(30.31552923264246),\n",
       "  np.float64(22.12983768359827),\n",
       "  np.float64(25.28769898366665),\n",
       "  np.float64(25.499056112049818),\n",
       "  np.float64(27.680853135123552),\n",
       "  np.float64(24.222195876058763),\n",
       "  np.float64(27.136528096709867),\n",
       "  np.float64(22.976299806447052),\n",
       "  np.float64(23.609315329449753)],\n",
       " 'MAE': [np.float64(71.24995843697477),\n",
       "  np.float64(73.9819889579832),\n",
       "  np.float64(64.01855542857142),\n",
       "  np.float64(68.72635242016807),\n",
       "  np.float64(65.4872769579832),\n",
       "  np.float64(67.26538764705882),\n",
       "  np.float64(67.15934848739495),\n",
       "  np.float64(69.83040447058823),\n",
       "  np.float64(62.802611630252095),\n",
       "  np.float64(66.60447098305086)],\n",
       " 'R2': [np.float64(-0.030022921636775113),\n",
       "  np.float64(-0.04065523720950792),\n",
       "  np.float64(0.14172604395700705),\n",
       "  np.float64(0.11532652790885922),\n",
       "  np.float64(0.029370889723075222),\n",
       "  np.float64(0.08989302953548506),\n",
       "  np.float64(0.0006745962956150597),\n",
       "  np.float64(0.08663399874504696),\n",
       "  np.float64(0.12220360482103498),\n",
       "  np.float64(-0.017799335900531288)],\n",
       " 'R2log': [np.float64(-0.02626921393274939),\n",
       "  np.float64(-0.06533469261792768),\n",
       "  np.float64(0.1435242809749313),\n",
       "  np.float64(0.11978682093705595),\n",
       "  np.float64(0.009270577813883296),\n",
       "  np.float64(0.06683138787061538),\n",
       "  np.float64(-0.009081717356640873),\n",
       "  np.float64(0.09143428211038784),\n",
       "  np.float64(0.10310147327048169),\n",
       "  np.float64(-0.04204502871911542)],\n",
       " 'coverage [%]': [np.float64(89.07563025210085),\n",
       "  np.float64(86.5546218487395),\n",
       "  np.float64(94.9579831932773),\n",
       "  np.float64(91.59663865546219),\n",
       "  np.float64(90.75630252100841),\n",
       "  np.float64(94.9579831932773),\n",
       "  np.float64(89.07563025210085),\n",
       "  np.float64(91.59663865546219),\n",
       "  np.float64(90.75630252100841),\n",
       "  np.float64(88.98305084745762)],\n",
       " 'coverage_distance [%]': [np.float64(88.23529411764706),\n",
       "  np.float64(87.39495798319328),\n",
       "  np.float64(91.59663865546219),\n",
       "  np.float64(94.11764705882352),\n",
       "  np.float64(92.43697478991596),\n",
       "  np.float64(95.7983193277311),\n",
       "  np.float64(84.87394957983193),\n",
       "  np.float64(90.75630252100841),\n",
       "  np.float64(91.59663865546219),\n",
       "  np.float64(89.83050847457628)],\n",
       " 'interval_size ': [np.float64(277.238769759395),\n",
       "  np.float64(271.31560784428575),\n",
       "  np.float64(287.5235588003194),\n",
       "  np.float64(276.6366781362185),\n",
       "  np.float64(278.7068004569916),\n",
       "  np.float64(287.3735841266554),\n",
       "  np.float64(279.8209187587563),\n",
       "  np.float64(277.10052915203363),\n",
       "  np.float64(281.6899356733278),\n",
       "  np.float64(281.22404137342374)],\n",
       " 'interval_size_distance ': [np.float64(264.64519211052107),\n",
       "  np.float64(266.88919665124376),\n",
       "  np.float64(265.35500827373113),\n",
       "  np.float64(275.3594316585378),\n",
       "  np.float64(275.56137918981517),\n",
       "  np.float64(268.0697546629748),\n",
       "  np.float64(266.1692028110924),\n",
       "  np.float64(267.22627735650417),\n",
       "  np.float64(269.6310930325042),\n",
       "  np.float64(275.3384828048475)],\n",
       " 'interval_log_size': [np.float64(0.3845663675417704),\n",
       "  np.float64(0.3831747290031815),\n",
       "  np.float64(0.3969233015263729),\n",
       "  np.float64(0.38727977153160403),\n",
       "  np.float64(0.3810047599609945),\n",
       "  np.float64(0.4022766574937263),\n",
       "  np.float64(0.400148257029499),\n",
       "  np.float64(0.3902292355474103),\n",
       "  np.float64(0.38929746279706057),\n",
       "  np.float64(0.3868466625405309)],\n",
       " 'interval_log_size_distance': [np.float64(0.36952632732977403),\n",
       "  np.float64(0.38717860890497613),\n",
       "  np.float64(0.36670188650732777),\n",
       "  np.float64(0.38857870378194487),\n",
       "  np.float64(0.38135712409127437),\n",
       "  np.float64(0.37635369345660885),\n",
       "  np.float64(0.3822655119050427),\n",
       "  np.float64(0.37747466108788535),\n",
       "  np.float64(0.3754099828127478),\n",
       "  np.float64(0.38244559928246863)]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BoundaryC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
